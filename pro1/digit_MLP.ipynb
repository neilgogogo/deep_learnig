{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#直接导入出现http403错误\n",
    "from six.moves import urllib\n",
    "# 直接导入出现http403错误\n",
    "# have to add a header to your urllib request (due to that site moving to Cloudflare protection)\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "#*********************** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PAIRS = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N_PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 14, 14])\n",
      "torch.Size([1000, 2])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000, 2, 14, 14])\n",
      "torch.Size([1000, 2])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_classes.shape)\n",
    "print(train_target.shape)\n",
    "print(test_input.shape)\n",
    "print(test_classes.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(test_input[i][0], cmap='gray')\n",
    "  plt.title(\"Value: {}\".format(train_classes[i][0]))  \n",
    "  plt.tight_layout()\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 14, 14])\n",
      "torch.Size([1000, 392])\n"
     ]
    }
   ],
   "source": [
    "# 将两个图片拼接成一个1*392的tensor，为进入MLP网络进行准备。\n",
    "print(train_input.shape)\n",
    "tran_train_input=train_input.view(-1,2*14*14)\n",
    "print(tran_train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 392])\n"
     ]
    }
   ],
   "source": [
    "#同理对测试数据集进行相同的操作\n",
    "tran_test_input=test_input.view(-1,2*14*14)\n",
    "print(tran_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MLP_Net(nn.Module):\n",
    "#     def __init__(self, num_hidden_1,num_hidden_2,num_hidden_3,num_hidden_4):\n",
    "#         super(Test_MLPmodel, self).__init__()\n",
    "#         self.linear1 = nn.Linear(2*14*14, 300)\n",
    "#         self.linear2 = nn.Linear(300, 200)\n",
    "#         self.linear3 = nn.Linear (200, 100)\n",
    "#         self.linear4 = nn.Linear (100, 50)\n",
    "#         self.linear_out = nn.Linear(num_hidden_4,2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.linear1(x.view(-1,2*14*14)))\n",
    "#         x = F.relu(self.linear2(x))\n",
    "#         x = F.relu(self.linear3(x))\n",
    "#         x = F.relu(self.linear4(x))\n",
    "#         x = self.linear_out(x)       \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(2*14*14, 300)\n",
    "        self.linear2 = nn.Linear(300, 200)\n",
    "        self.linear3 = nn.Linear (200, 100)\n",
    "        self.linear4 = nn.Linear (100, 50)\n",
    "        self.linear5 = nn.Linear (50, 20)\n",
    "        self.linear_out = nn.Linear(20,2)\n",
    "        # training parameter\n",
    "        self.batch_size = 20\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.num_epochs = 25\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x.view(-1,2*14*14)))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = F.relu(self.linear4(x))\n",
    "        x = F.relu(self.linear5(x))\n",
    "        x = self.linear_out(x)       \n",
    "        return x\n",
    "     # Training Function\n",
    "\n",
    "    def trainer(self, train_input, train_target):\n",
    "        \"\"\"\n",
    "        Train the model on a training set\n",
    "        :param train_input: Training features\n",
    "        :param train_target: Training labels\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        self.train()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for batch_idx in range(0,train_input.size(0),self.batch_size):\n",
    "                output = self(train_input[batch_idx:batch_idx+self.batch_size]) \n",
    "                loss = self.criterion(output, train_target[batch_idx:batch_idx+self.batch_size])  \n",
    "                self.optimizer.zero_grad()                          #清零梯度\n",
    "                loss.backward()                                #反向求梯度\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if not batch_idx % 50:\n",
    "                    print ('Epoch: %03d/%03d | Batch %03d/%03d | Loss: %.6f' \n",
    "                           %(epoch+1, self.num_epochs, batch_idx, \n",
    "                             len(train_input), loss))\n",
    "            print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "        print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n",
    "         # Test error\n",
    "\n",
    "    def compute_error(self, input_data, target):\n",
    "        \"\"\"\n",
    "        Compute the number of error of the model on a test set\n",
    "        :param input_data: test features\n",
    "        :param target: test target\n",
    "        :return: error rate of the input data\n",
    "        \"\"\"  \n",
    "    \n",
    "        #测试模型\n",
    "        self.eval()      #测试模式，关闭正则化\n",
    "        errors = 0\n",
    "        for idx in range(0,input_data.size(0),self.batch_size):\n",
    "            input_batch=input_data.narrow(0,idx,self.batch_size)\n",
    "            outputs = self(input_batch)\n",
    "            _, predicted = torch.max(outputs, 1)   #返回值和索引\n",
    "            target_labels = target.narrow(0, idx, self.batch_size)\n",
    "            errors += torch.sum(predicted != target_labels)\n",
    "\n",
    "        return float(errors)*100/input_data.size(0)\n",
    "    def save_model(self,model_name):\n",
    "        \"\"\"\n",
    "        Save the model to this folder\n",
    "        :param model_name: the model name, e.g. CNN_Net.pth\n",
    "        \"\"\"         \n",
    "        torch.save(self, './model/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MLP_Net()\n",
    "my_model.save_model('MLP_Net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.719313\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.815643\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.674651\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.689790\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.705986\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.776399\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.689004\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.700999\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.740349\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.699651\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.840973\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.709207\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.670301\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.702534\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.650407\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.818234\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.605942\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.684731\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.688393\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.696726\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.643416\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.730058\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.697406\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.704394\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.656725\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.700376\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.667306\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.638358\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.748884\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.672405\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.751504\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.699179\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.666082\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.674499\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.670940\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.774002\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.589063\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.594150\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.681825\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.592815\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.611455\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.685497\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.679099\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.612826\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.595734\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.533353\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.471267\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.660308\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.633391\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.645612\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.541989\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.574901\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.656343\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.629453\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.498173\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.662844\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.613426\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.538109\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.680662\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.485081\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.686603\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.378323\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.748281\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.589853\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.501961\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.521858\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.586182\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.331018\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.554166\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.387590\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.600716\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.287892\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.535627\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.452085\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.469894\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.608290\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.476655\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.506133\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.495660\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.610587\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.478936\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.538246\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.422405\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.473012\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.411287\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.516831\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.442912\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.268117\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.314045\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.239023\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.353455\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.282499\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.261764\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.414747\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.273169\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.461216\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.400105\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.316840\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.494930\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.160007\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.211207\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.403380\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.247309\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.264900\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.375685\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.466994\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.212147\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.526969\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.305704\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.356953\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.377187\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.239148\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.303961\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.459874\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.339262\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.213343\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.159624\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.445686\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.193944\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.163964\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.269251\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.221075\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.250645\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.402815\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.242389\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.154929\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.184464\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.163758\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.248492\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.040714\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.247342\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.287953\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.156579\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.221910\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.177986\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.313991\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.239023\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.095513\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.231903\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.367403\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.139089\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.421865\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.385113\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.241486\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.140387\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.110267\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.201806\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.107928\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.274597\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.050148\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.190187\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.182465\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.105280\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.706052\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.346905\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.160990\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.138845\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.491617\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.490725\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.120144\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.294846\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.150947\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.177809\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.186360\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.031674\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.151791\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.067753\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.207769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.183072\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.117271\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.033341\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.050317\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.129350\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.050803\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.045798\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.035254\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.129360\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.180563\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.052348\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.007700\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.005495\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.012790\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.037438\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.195293\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.003301\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.084920\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.000893\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.006135\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.004612\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.026644\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.454048\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.002624\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.039055\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.134596\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.008698\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.010822\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.027040\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.026383\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.006169\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.087967\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.043309\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.005643\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.232457\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.134261\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.008027\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.025076\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.033855\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.048029\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.003894\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.005736\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.010310\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.072497\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.009958\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.131426\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.001159\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.082964\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.005129\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.020995\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.005900\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.010811\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.017211\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.000477\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.183960\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.045240\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.092081\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.001989\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.007375\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.059108\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.008879\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.000666\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.202576\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.001174\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.003643\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.016199\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.003880\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.008907\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.003129\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.002128\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.205383\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.000390\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000269\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.018793\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.000405\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.062950\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.001582\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.035889\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.002419\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.032709\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.005570\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.038117\n",
      "Time elapsed: 0.05 min\n",
      "Total Training Time: 0.05 min\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "# my_model.trainer(tran_test_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error : 0.0% \n",
      "Test error : 17.3%\n",
      "The total number of the parameters is: 204312\n"
     ]
    }
   ],
   "source": [
    "# output the train error and test error\n",
    "# print(\"Train error : %.1f%% \\nTest error : %.1f%%\" %\n",
    "#       (my_model.compute_error(tran_train_input, train_target),\n",
    "#        my_model.compute_error(tran_test_input, test_target)))\n",
    "\n",
    "# print(\"The total number of the parameters is: %d\" % (sum(p.numel() for p in my_model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_accuracy(net, test_input,test_target):\n",
    "# # 在训练模型的时候前面加上model.train()，在测试模型的时候前面加上model.eval(),以切换到测试模式\n",
    "#     net.eval()\n",
    "#     correct_pred, num_examples = 0, 0\n",
    "# # 而with torch.no_grad()则主要是用于停止autograd模块的工作，\n",
    "# # 以起到加速和节省显存的作用，具体行为就是停止gradient计算，\n",
    "# # 从而节省了GPU算力和显存，但是并不会影响dropout和batchnorm层的行为。\n",
    "#     with torch.no_grad():\n",
    "# #         for features, targets in data_loader:\n",
    "#         for idx in range(test_input.size(0)):\n",
    "# #             features = features.view(-1, 14*14)\n",
    "#             features= test_input[idx]\n",
    "#             targets = test_target[idx]\n",
    "#             logits, probas = net(features)\n",
    "#             _, predicted_labels = torch.max(probas, 1)\n",
    "#             num_examples += targets.size(0)\n",
    "#             correct_pred += (predicted_labels == targets).sum()\n",
    "#         return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.790752\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.767673\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.659127\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.634099\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.639099\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.667664\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 1.000162\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.425860\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.643506\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.506112\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.290680\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.382691\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.518659\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.526801\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.641019\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.511901\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.587581\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.287096\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.472177\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.282751\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.215306\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.244440\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.366143\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.295149\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.465478\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.494893\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.369922\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.185639\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.509416\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.199966\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.170054\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.206759\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.434742\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.262126\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.345273\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.353759\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.224231\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.069473\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.170160\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.047498\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.083207\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.072755\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.268968\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.103331\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.222367\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.195216\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.264310\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.048482\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.096570\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.107475\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.165220\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.123737\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.458995\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.082932\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.151268\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.428530\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.111247\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.039345\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.261809\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.044272\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.088862\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.127789\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.098857\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.055702\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.225337\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.095888\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.180518\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.072470\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.030563\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.024591\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.013061\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.009190\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.034865\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.516602\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.212273\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.031727\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.034130\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.017004\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.003594\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.003468\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.160665\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.373855\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.055179\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.253900\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.559113\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.191254\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.122977\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.046138\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.058594\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.037616\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.001989\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.137551\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.492520\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.009901\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.113607\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.250298\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.270907\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.406009\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.052248\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.058194\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.061944\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.033660\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.046991\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.040622\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.100384\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.442392\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.265497\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.007506\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.030143\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.000728\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.367804\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.011723\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.033931\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.008912\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.009735\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.077571\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.005006\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.008200\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.003060\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.001400\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.044627\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.000233\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.001326\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.001713\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.000932\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.004194\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.205773\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.020732\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.003046\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.014498\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.013553\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.003028\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.008274\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.011471\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.012018\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.005137\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.022019\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.000547\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.430181\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.013281\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.009555\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.012996\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.049681\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.004528\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.005650\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.008937\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.001975\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.000528\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.026259\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.336618\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.048360\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.017869\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.183320\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.005132\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.005510\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.043454\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.017360\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.013291\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.015221\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.000790\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.005439\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.033464\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.016847\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.003765\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.006315\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.010903\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.045576\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.000336\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.002032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.001372\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.077472\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.009597\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.035525\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.036187\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.046345\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.034227\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.184018\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.001543\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.007234\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.012196\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.003923\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.104608\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.008984\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.006147\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.058818\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.021643\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.000226\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.107466\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.005257\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.032959\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.004336\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.026453\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.015662\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.004623\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.014870\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.003986\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.000541\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.000067\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.079561\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.000286\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.000629\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.001817\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.001653\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.001201\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.112299\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.096994\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.001216\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.016910\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.004843\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.007674\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.004186\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.006379\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.010099\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.002018\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.001364\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.000990\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.001282\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.000559\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.025883\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.000885\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.000606\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.002372\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.005081\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.000205\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.000525\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.000171\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.001028\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.000428\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.000045\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.000045\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.000122\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.000067\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.000669\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.000059\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.000049\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.000012\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.000086\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.000157\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.000015\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.000011\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000077\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.000020\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.000290\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.000017\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.000022\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.000005\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.000042\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000057\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.000004\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000003\n",
      "Time elapsed: 0.05 min\n",
      "Total Training Time: 0.05 min\n",
      "Train error : 0.0% \n",
      "Test error : 18.4%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.720814\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.614432\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.403787\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.398386\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.509667\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.687564\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.712622\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.675120\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.500373\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.472530\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.591596\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.432808\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.275419\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.290969\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.569722\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.731723\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.630751\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.649581\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.411033\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.394969\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.589380\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.407551\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.210499\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.199166\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.309594\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.722209\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.606131\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.552610\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.375037\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.321728\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.382205\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.312743\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.171083\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.228217\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.188980\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.399001\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.189642\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.486699\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.304578\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.244646\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.244152\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.135028\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.033498\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.023651\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.055962\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.341684\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.023457\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.496608\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.285886\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.261979\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.212048\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.183082\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.056318\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.059625\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.420143\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.272916\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.093537\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.492959\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.141515\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.265832\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.197305\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.118499\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.179702\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.199440\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.030233\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.153353\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.030680\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.400937\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.186598\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.213848\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.084159\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.071120\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.141588\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.042411\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.678253\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.216936\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.079081\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.162935\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.276186\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.228080\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.175655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.130877\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.088768\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.100501\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.047660\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.009793\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.018071\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.238185\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.128609\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.044516\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.184441\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.112507\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.157008\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.083522\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.137283\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.113469\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.358977\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.091227\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.034214\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.061472\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.023387\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.067138\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.019343\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.209655\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.015259\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.319912\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.011822\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.534716\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.069052\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.007553\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.018264\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.010024\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.058682\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.025194\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.000490\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.008988\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.000757\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.022917\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.043003\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.002728\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.003143\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.003617\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.038653\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.282557\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.012616\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.019767\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.003803\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.029469\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.006851\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.043002\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.175919\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.001685\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.004959\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.002183\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.006856\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.038771\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.004022\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.033236\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.168222\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.007689\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.007071\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.045456\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.006895\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.008383\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.006757\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.005050\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.018563\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.008136\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.033335\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.089875\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.142267\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.088466\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.025476\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.018068\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.010790\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.010559\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.133828\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.060308\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.030123\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.033279\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.005792\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.023081\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.035900\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.120109\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.140951\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.012245\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.036303\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.097223\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.005304\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.064401\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.054791\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.186064\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.008659\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.011937\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.010396\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.023243\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.002166\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.051778\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.106771\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.027307\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.013203\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.001355\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.007959\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.018450\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.002503\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.001878\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.003170\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.003720\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.001461\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.013956\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.022968\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.001496\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.004363\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.001928\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.308003\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.049167\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.008070\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.018888\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.011803\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.012484\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.002034\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.004973\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.030172\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.087707\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.001180\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.005430\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.001630\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.009892\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.031939\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.090688\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.006033\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.002268\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.001365\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.000545\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.001836\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.000366\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.000244\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.012411\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.000619\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.000195\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.000124\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.013398\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.000460\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.000480\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.000751\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.000180\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.000115\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.000718\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.000184\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.000980\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.000367\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.000088\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.001240\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.000226\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.000233\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.000164\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.000031\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.000709\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.000081\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.000085\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000045\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.000041\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.000262\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.000106\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.000137\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.000091\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.000021\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.000043\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000067\n",
      "Time elapsed: 0.05 min\n",
      "Total Training Time: 0.05 min\n",
      "Train error : 0.0% \n",
      "Test error : 18.1%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.672710\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.710425\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.618455\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.578670\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.532406\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.480445\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.522310\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.459847\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.392403\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.434759\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.466344\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.317155\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.354621\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.465535\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.606514\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.432998\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.324433\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.300151\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.306556\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.305431\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.404134\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.170434\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.353476\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.355548\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.432984\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.507447\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.263707\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.230308\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.299016\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.308296\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.419941\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.117821\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.169353\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.319497\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.234363\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.157222\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.260970\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.204206\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.291337\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.243412\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.163048\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.090994\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.306367\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.196723\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.153233\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.174470\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.402608\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.097638\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.106141\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.458481\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.291505\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.047719\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.149802\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.243657\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.137962\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.035976\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.066478\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.008371\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.078678\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.208227\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.190470\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.063042\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.171664\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.139054\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.019191\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.189268\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.024032\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.035276\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.023904\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.105152\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.100415\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.132948\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.038973\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.067194\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.084750\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.046577\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.094251\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.030571\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.085602\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.154101\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.061861\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.021665\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.247884\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.009769\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.041913\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.008058\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.099382\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.058698\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.026998\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.148076\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.024180\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.045929\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.004397\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.009554\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.328314\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.042259\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.092566\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.016841\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.093198\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.010921\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.007540\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.329379\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.100296\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.056005\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.016813\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.087254\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.100825\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.010108\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.092926\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.009505\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.069321\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.008737\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.167118\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.012526\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.081849\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.342697\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.136248\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.006454\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.023131\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.009236\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.270774\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.006644\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.021783\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.071840\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.166680\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.069770\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.292273\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.006123\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.120663\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.068739\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.036183\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.011580\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.005446\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.011846\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.056231\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.001725\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.007691\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.153200\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.030352\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.003998\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.318433\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.001097\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.068717\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.002387\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.012916\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.001532\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.005408\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.000346\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.004410\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.001622\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.000745\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.002074\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.000609\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.001697\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.009329\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.002108\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.133170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.000693\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.001834\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.000624\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.003089\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.002044\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.010803\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.003727\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.001888\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.000277\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.001949\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.001796\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.003201\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.000073\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.056820\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.000217\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.000147\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.000566\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.001454\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.000302\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.010037\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.000100\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.000313\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.000090\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.000889\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.009407\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.000812\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.085827\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.004272\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.000048\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.001163\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.001409\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.001029\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.010299\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.000651\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.000733\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.001562\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.007759\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.002366\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.000072\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.000318\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.001703\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.001261\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.000156\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.005040\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.000550\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.000119\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.000213\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.005935\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.000090\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.000452\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.000203\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.002862\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.003938\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.041410\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.000059\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.000597\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.000103\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.002558\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.000298\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.000029\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.049628\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.000371\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.000017\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.000409\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.032015\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.271544\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.011963\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.115956\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.000616\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.172913\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.044341\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.040373\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.014193\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.001896\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.001252\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.000345\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.056826\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.008077\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.212814\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.108108\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.002106\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.027703\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.093085\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.001396\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.074907\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.002100\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.066297\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.049989\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.001305\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.003114\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.001024\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.006457\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000480\n",
      "Time elapsed: 0.05 min\n",
      "Total Training Time: 0.05 min\n",
      "Train error : 0.9% \n",
      "Test error : 22.1%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.709398\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.552164\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.632607\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.642129\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.574263\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.618986\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.816236\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.510784\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.561884\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.422454\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.349717\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.343865\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.489392\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.526889\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.626386\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.485970\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.493123\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.345491\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.546600\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.303325\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.308428\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.232216\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.360026\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.347306\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.603262\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.334189\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.399215\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.475393\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.281531\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.223334\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.148587\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.226760\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.286648\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.371440\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.493311\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.283666\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.523672\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.311799\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.115855\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.128183\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.379428\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.127866\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.230777\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.358748\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.169258\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.445902\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.422634\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.238965\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.241374\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.089709\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.038610\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.344420\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.587802\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.158541\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.297283\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.379606\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.513777\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.226168\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.111995\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.063985\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.027749\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.515322\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.336153\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.281042\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.327760\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.275462\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.243402\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.145828\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.060266\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.031841\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.019295\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.162402\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.120650\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.186908\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.131981\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.090959\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.118589\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.078478\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.078758\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.023872\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.070052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.029176\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.144400\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.153534\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.147361\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.065773\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.223272\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.128138\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.049109\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.071834\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.031711\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.017833\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.173486\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.010876\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.004304\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.019136\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.039643\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.009319\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.007203\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.094646\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.004414\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.036235\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.023970\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.023076\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.004782\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.020386\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.106966\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.032933\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.020329\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.017987\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.002591\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.021074\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.019827\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.015148\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.042538\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.011764\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.065871\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.093527\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.002148\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.004853\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.000703\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.005881\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.024068\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.011518\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.002573\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.019476\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.082488\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.005895\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.012309\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.007654\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.001361\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.020326\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.020853\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.060191\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.002960\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.308782\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.004152\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.012260\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.077339\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.018023\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.027794\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.038514\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.297808\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.034097\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.086347\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.018523\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.036763\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.010459\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.093896\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.024081\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.095396\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.020964\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.007961\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.022058\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.002449\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.016125\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.056479\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.083697\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.000780\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.001704\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.001547\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.003474\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.038588\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.098774\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.004360\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.001867\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.026099\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.002608\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.015152\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.000577\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.002782\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.022291\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.003232\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.001111\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.024108\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.005881\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.001205\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.001320\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.001518\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.001176\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.000893\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.000454\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.001359\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.003117\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.003375\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.000189\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.001601\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.003610\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.010273\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.002220\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.142513\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.008126\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.033740\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.020798\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.029046\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.011849\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.094239\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.008455\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.000735\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.000909\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.000400\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.007250\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.000348\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.004685\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.013801\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.001803\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.021986\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.058803\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.006684\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.094252\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.005563\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.016139\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.007767\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.000757\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.055917\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.001025\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.003548\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.004261\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.014179\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.001219\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.000134\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.000772\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.007094\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.000082\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.008478\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.004218\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.000495\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.000194\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.000073\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.000172\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.001318\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.000171\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.002334\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.174830\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.216717\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.019710\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.027087\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.054032\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.149053\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.010103\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.001172\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.008987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.006517\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.078987\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.004276\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.001105\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.008426\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000061\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.000372\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000339\n",
      "Time elapsed: 0.05 min\n",
      "Total Training Time: 0.05 min\n",
      "Train error : 0.0% \n",
      "Test error : 18.5%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.696470\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.677694\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.652922\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.628598\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.656930\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.821374\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.596308\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.490033\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.500372\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.629832\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.680523\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.418469\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.527435\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.633579\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.649466\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.728970\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.488353\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.495110\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.404643\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.644846\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.664682\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.273069\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.580098\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.658830\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.409778\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.362615\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.437585\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.388750\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.347375\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.448040\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.455442\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.162257\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.457683\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.394852\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.297792\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.280842\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.302921\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.238297\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.357480\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.361104\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.470301\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.096439\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.158171\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.115610\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.124772\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.355827\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.319193\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.205978\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.322031\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.382697\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.309855\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.190061\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.140597\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.364300\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.142848\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.161358\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.294033\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.151037\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.205272\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.220217\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.262865\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.060515\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.033814\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.102494\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.349177\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.088911\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.105862\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.132792\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.101399\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.524929\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.893802\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.290383\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.490861\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.298982\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.202241\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.197891\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.210758\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.153256\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.251474\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.085994\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.081539\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.149562\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.552609\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.085704\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.159122\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.096363\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.252273\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.310069\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.050151\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.072556\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.063901\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.160199\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.229463\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.072054\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.061620\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.085276\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.083819\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.074535\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.059555\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.026988\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.063307\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.061801\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.006293\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.216375\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.005545\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.072043\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.047798\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.054566\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.044605\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.100450\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.030761\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.011672\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.142524\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.049972\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.226607\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.001719\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.170524\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.019981\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.002987\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.286453\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.014970\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.017284\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.000622\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.000824\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.011116\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.001436\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.003771\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.005289\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.015459\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.090560\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.034096\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.005640\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.013509\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.001468\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.012226\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.001278\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.004296\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.004032\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.010941\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.006021\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.003666\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.008311\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.001691\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.108813\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.027089\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.000521\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.039358\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.058261\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.033452\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.029193\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.172540\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.027668\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.002737\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.000549\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.010931\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.001474\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.023472\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.004160\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.021131\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.001225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.083460\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.000183\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.000920\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.000666\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.002180\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.011099\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.214512\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.006641\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.019976\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.014875\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.001188\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.001510\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.005283\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.007510\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.000646\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.009983\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.038830\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.000685\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.016163\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.001095\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.052380\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.000256\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.000350\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.000506\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.036757\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.114521\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.004690\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.002238\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.007883\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.001458\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.021186\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.001360\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.004649\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.001138\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.000318\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.035710\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.017044\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.000621\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.000863\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.001052\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.000586\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.003227\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.018810\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.001951\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.000136\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.032656\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.160197\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.039598\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.004295\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.144760\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.055346\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.005134\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.000431\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.000529\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.000128\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.002295\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.201988\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.000688\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.024994\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.002662\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.000345\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.044753\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.001239\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.000020\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.000620\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.000796\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.000125\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.000010\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.001485\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.000031\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.000024\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.000047\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.000213\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.000005\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.000100\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.000089\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.000025\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.000006\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.000185\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.000010\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000011\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.000025\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.000184\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.000003\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.000055\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.000055\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.000016\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000004\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.000097\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000007\n",
      "Time elapsed: 0.06 min\n",
      "Total Training Time: 0.06 min\n",
      "Train error : 0.0% \n",
      "Test error : 19.5%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.690474\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.637554\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.791490\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.527463\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.583887\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.486994\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.635598\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.582879\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.519314\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.394986\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.509587\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.524446\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.476184\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.447950\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.512516\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.473593\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.462969\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.381201\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.302853\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.250911\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.496329\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.539300\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.297359\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.359579\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.459242\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.257495\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.383333\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.474003\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.297774\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.404926\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.355106\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.413109\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.246173\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.155340\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.357660\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.336466\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.290434\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.185600\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.134287\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.129519\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.209238\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.304883\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.127586\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.093343\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.254317\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.210669\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.217532\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.069573\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.085633\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.047869\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.077973\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.090098\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.056252\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.131876\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.122042\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.280520\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.169640\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.053497\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.030057\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.124641\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.068911\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.164106\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.225235\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.121901\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.106381\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.423542\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.116454\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.130477\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.015982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.061826\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.037251\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.241138\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.001388\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.057926\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.075545\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.069479\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.077933\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.024864\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.045561\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.051241\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.035786\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.037911\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.002150\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.048782\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.039108\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.044343\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.023742\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.034306\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.141563\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.018016\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.095355\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.240866\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.001487\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.009255\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.002554\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.040505\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.089431\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.015494\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.014039\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.039854\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.151770\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.229110\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.013742\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.009406\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.031982\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.080330\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.226405\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.103258\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.003382\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.040072\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.017091\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.082220\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.031939\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.000227\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.008061\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.033160\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.262989\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.023607\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.066179\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.015102\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.032880\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.155707\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.000718\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.001871\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.235113\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.087421\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.042974\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.008993\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.003812\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.014636\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.020905\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.085242\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.027353\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.022562\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.059705\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.020730\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.008900\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.044072\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.000082\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.011448\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.071480\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.156210\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.030632\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.017625\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.055951\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.004064\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.001866\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.002131\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.026414\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.009115\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.091318\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.064240\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.015401\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.023855\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.096265\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.013954\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.235043\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.224823\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.014650\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.047453\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.025869\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.085391\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.024303\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.028621\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.011636\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.032601\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.000929\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.248803\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.004791\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.038528\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.006635\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.030397\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.038550\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.003215\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.026089\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.027607\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.010383\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.029661\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.000797\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.000436\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.002932\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.001018\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.002023\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.006987\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.000886\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.001170\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.000424\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.000050\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.000321\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.010362\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.001330\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.000241\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.000142\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.000046\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.000084\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.000270\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.000918\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.000082\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.000003\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.000023\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.000288\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.000126\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.000137\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.000055\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.000091\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.000460\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.000036\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.000009\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.000003\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.000020\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.000191\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.000086\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.000090\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.000039\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.000057\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.000285\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.000030\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.000004\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.000001\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.000012\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.000110\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.000025\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.000029\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.000016\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.000026\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.000113\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.000024\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.000001\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.000001\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.000005\n",
      "Time elapsed: 0.06 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.000041\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.000008\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.000011\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.000007\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.000012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.000053\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.000021\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.000000\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.000000\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.000003\n",
      "Time elapsed: 0.06 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000022\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.000004\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.000005\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.000003\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.000007\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.000031\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.000018\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000000\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.000000\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000002\n",
      "Time elapsed: 0.06 min\n",
      "Total Training Time: 0.06 min\n",
      "Train error : 0.0% \n",
      "Test error : 17.3%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.781901\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.833795\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.634596\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.536084\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.575488\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.529402\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.492346\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.546780\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.443740\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.326972\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.549518\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.502452\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.221382\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.458034\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.522071\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.498621\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.280318\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.370598\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.253314\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.217056\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.399012\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.281504\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.098176\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.336014\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.429362\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.337853\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.258620\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.236400\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.185362\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.180927\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.289821\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.344440\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.050127\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.168145\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.295967\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.313932\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.182111\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.361301\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.218385\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.097840\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.067843\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.433831\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.021028\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.141894\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.234238\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.350004\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.141006\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.190197\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.300340\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.317474\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.147679\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.098666\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.011417\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.137966\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.172903\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.414095\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.094473\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.165203\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.068684\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.024981\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.034431\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.024206\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.123754\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.200636\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.245792\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.186845\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.118914\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.226325\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.105967\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.026934\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.020877\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.015355\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.035837\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.039557\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.424854\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.300320\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.095076\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.125816\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.093966\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.118924\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.065325\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.094814\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.030431\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.002404\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.394820\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.068765\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.712649\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.143217\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.217837\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.050163\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.049772\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.060461\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.007466\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.163075\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.050704\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.157646\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.202277\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.218590\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.101322\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.038632\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.037148\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.024940\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.008004\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.004251\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.011042\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.036775\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.007075\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.107697\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.014406\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.020413\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.007068\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.009011\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.003452\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.011657\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.010567\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.017233\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.002769\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.003509\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.003798\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.001605\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.005389\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.428300\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.016633\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.020748\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.146515\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.091765\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.039015\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.001904\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.011699\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.002953\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.024866\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.007984\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.000763\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.003509\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.049141\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.061056\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.012733\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.250264\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.003149\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.004383\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.004508\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.023172\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.001802\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.029204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.094471\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.068409\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.008722\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.010607\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.004091\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.042672\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.014427\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.019793\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.007275\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.017037\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.017558\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.018670\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.009439\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.004280\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.025733\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.002004\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.001573\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.000917\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.000039\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.000106\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.000552\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.000599\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.001097\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.000357\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.000064\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.000020\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.000035\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.000170\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.000016\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.000007\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.000279\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.000106\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.000229\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.000140\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.000018\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.000100\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.000177\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.024138\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.000006\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.000036\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.000478\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.000202\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.000164\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.000020\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.000047\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.000018\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.000740\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.206609\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.000858\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.002589\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.011702\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.014669\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.005824\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.017870\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.079579\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.002377\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.001840\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.090021\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.009538\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.004111\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.004404\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.001255\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.010703\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.029408\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.001282\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.105502\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.023906\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.000855\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.005215\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.000967\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.083239\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.051130\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.049262\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.008125\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.002662\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.010996\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.003818\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.018362\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.000862\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.207452\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.006122\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.115644\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.006668\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.027267\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.109282\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.003092\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.022083\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.005210\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.002251\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.000645\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.001510\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.000848\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.000682\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.000636\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.000325\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.000044\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000499\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.000120\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.000122\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.000182\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.000457\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.000148\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.000305\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000192\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.000068\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000010\n",
      "Time elapsed: 0.06 min\n",
      "Total Training Time: 0.06 min\n",
      "Train error : 0.0% \n",
      "Test error : 19.6%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.765299\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.565479\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.611705\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.715674\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.726271\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.530904\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.509968\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.495102\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.589782\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.402148\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.560789\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.306233\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.630917\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.496573\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.416590\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.512136\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.371239\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.524931\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.369459\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.276207\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.499142\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.230268\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.445499\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.400412\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.295201\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.181729\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.155718\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.414737\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.352267\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.185431\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.290456\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.298405\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.228539\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.104847\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.127625\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.175476\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.063067\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.290569\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.154953\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.227240\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.259698\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.066445\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.668713\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.122904\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.271790\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.137728\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.031459\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.347309\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.077511\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.126273\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.295910\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.102175\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.160275\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.058177\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.077944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.028231\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.171891\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.165535\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.698161\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.101556\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.164916\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.085780\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.124049\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.090980\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.060987\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.025850\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.252642\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.372867\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.074315\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.049170\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.142898\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.128564\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.086841\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.095111\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.119205\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.016584\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.141150\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.034553\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.144178\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.135959\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.105726\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.153265\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.132536\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.098438\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.040497\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.114117\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.100838\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.019491\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.219498\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.206872\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.229964\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.195482\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.099660\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.093930\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.069057\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.029090\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.018512\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.135612\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.058118\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.050644\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.081338\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.023636\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.314011\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.031810\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.037188\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.003184\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.044731\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.094139\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.119760\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.048206\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.186579\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.104899\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.032903\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.039953\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.035688\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.019726\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.002224\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.291321\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.010404\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.146366\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.143882\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.009194\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.108166\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.041503\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.009084\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.020626\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.010349\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.008863\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.004862\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.059394\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.014000\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.078285\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.009839\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.017824\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.010055\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.201916\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.004720\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.014505\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.000590\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.000207\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.001813\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.000505\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.000850\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.000231\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.001198\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.000021\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.000235\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.000191\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.000017\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.072794\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.299067\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.040693\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.088327\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.092562\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.311254\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.003675\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.023794\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.007595\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.016468\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.002621\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.032768\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.018313\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.018694\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.004879\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.011126\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.039990\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.014039\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.000953\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.013396\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.000159\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.252061\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.003149\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.003674\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.011050\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.073710\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.000763\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.176059\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.001031\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.188348\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.002180\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.398495\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.010515\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.029791\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.049042\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.041731\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.000514\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.015314\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.052013\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.000284\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.000866\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.001044\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.000545\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.006150\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.009290\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.004530\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.001365\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.000962\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.000362\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.000074\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.000112\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.000219\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.000630\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.000297\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.000448\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.000980\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.005123\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.000232\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.001108\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.015879\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.039601\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.012105\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.000441\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.005088\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.004063\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.004138\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.000733\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.000892\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.000120\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.000047\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.004082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.05 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.004534\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.005348\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.001718\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.001865\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.014225\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.000210\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.007079\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.001359\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.141414\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.002894\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.096702\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.000095\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.029252\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.229530\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.082370\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.004330\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.011605\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.000299\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.001706\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.003181\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000285\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.000213\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.028269\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.123181\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.004843\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.002189\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.012161\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000610\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.001520\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.001902\n",
      "Time elapsed: 0.06 min\n",
      "Total Training Time: 0.06 min\n",
      "Train error : 0.1% \n",
      "Test error : 19.1%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.751163\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.670516\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.626781\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.565994\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.521983\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.398513\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.392129\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.690538\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.531587\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.484688\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.525734\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.468127\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.454295\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.416387\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.498371\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.234266\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.272607\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.691908\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.449582\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.362890\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.521250\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.330058\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.285274\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.218960\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.343877\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.180836\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.157448\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.499765\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.348029\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.222132\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.312425\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.424613\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.200592\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.107325\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.362930\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.172961\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.205467\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.338020\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.447466\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.157657\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.198195\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.173987\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.198284\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.100124\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.146418\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.038462\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.177200\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.261451\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.319251\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.369796\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.408008\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.316700\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.117271\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.074637\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.212298\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.074786\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.107426\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.497899\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.104715\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.221823\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.049564\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.170302\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.100301\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.034889\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.015906\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.060759\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.005531\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.133668\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.034550\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.286889\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.015855\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.138973\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.171284\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.037638\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.178554\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.035124\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.038683\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.025847\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.147296\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.097132\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.016194\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.139127\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.016046\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.026211\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.035409\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.015631\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.023412\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.012476\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.217749\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.047609\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.046434\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.159021\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.022210\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.180893\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.156095\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.036072\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.030261\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.517347\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.123598\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.090523\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.019253\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.017458\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.269487\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.015216\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.177715\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.021874\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.009741\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.069746\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.206112\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.241857\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.004862\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.035127\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.049323\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.062412\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.026682\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.043219\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.019379\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.126785\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.011842\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.050921\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.043629\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.147972\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.066069\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.004515\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.092036\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.002712\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.001424\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.002354\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.015478\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.012458\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.000272\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.043163\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.009699\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.014485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.033287\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.006484\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.008210\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.052656\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.007516\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.007807\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.035504\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.012880\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.106011\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.107255\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.020009\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.004491\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.197515\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.030714\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.010414\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.053196\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.180622\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.058305\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.064566\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.010291\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.059532\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.004684\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.039771\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.035056\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.012826\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.010971\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.000656\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.016306\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.061558\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.012508\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.027470\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.001253\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.039855\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.014805\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.000239\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.000661\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.272263\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.041719\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.150406\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.084259\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.008144\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.025427\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.014907\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.005855\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.074679\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.000704\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.157988\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.041965\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.000697\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.001265\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.007527\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.004201\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.003457\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.034646\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.007452\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.004318\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.002260\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.001218\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.000942\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.000834\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.002807\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.003475\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.005123\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.000640\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.000267\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.000288\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.000056\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.000146\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.000371\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.000232\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.000291\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.000225\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.000157\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.000456\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.000138\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.000156\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.000034\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.000087\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.000215\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.000132\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.000201\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.000168\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.000111\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.000279\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.000091\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.000114\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.000025\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.000063\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.000164\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.000094\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.000154\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.000129\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.000083\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.000200\n",
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.000066\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.000088\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.000019\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.000048\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.000132\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.000072\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.000123\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.000102\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.000065\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.000153\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.000051\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.000070\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000015\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.000038\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.000110\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.000057\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.000101\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.000083\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.000052\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000121\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.000040\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000058\n",
      "Time elapsed: 0.06 min\n",
      "Total Training Time: 0.06 min\n",
      "Train error : 0.0% \n",
      "Test error : 17.9%\n",
      "The total number of the parameters is: 204312\n",
      "Epoch: 001/025 | Batch 000/1000 | Loss: 0.807101\n",
      "Epoch: 001/025 | Batch 100/1000 | Loss: 0.627250\n",
      "Epoch: 001/025 | Batch 200/1000 | Loss: 0.690720\n",
      "Epoch: 001/025 | Batch 300/1000 | Loss: 0.679764\n",
      "Epoch: 001/025 | Batch 400/1000 | Loss: 0.626787\n",
      "Epoch: 001/025 | Batch 500/1000 | Loss: 0.695921\n",
      "Epoch: 001/025 | Batch 600/1000 | Loss: 0.564369\n",
      "Epoch: 001/025 | Batch 700/1000 | Loss: 0.516891\n",
      "Epoch: 001/025 | Batch 800/1000 | Loss: 0.614625\n",
      "Epoch: 001/025 | Batch 900/1000 | Loss: 0.284552\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 002/025 | Batch 000/1000 | Loss: 0.432652\n",
      "Epoch: 002/025 | Batch 100/1000 | Loss: 0.252616\n",
      "Epoch: 002/025 | Batch 200/1000 | Loss: 0.624323\n",
      "Epoch: 002/025 | Batch 300/1000 | Loss: 0.604226\n",
      "Epoch: 002/025 | Batch 400/1000 | Loss: 0.321191\n",
      "Epoch: 002/025 | Batch 500/1000 | Loss: 0.706979\n",
      "Epoch: 002/025 | Batch 600/1000 | Loss: 0.500284\n",
      "Epoch: 002/025 | Batch 700/1000 | Loss: 0.381146\n",
      "Epoch: 002/025 | Batch 800/1000 | Loss: 0.507326\n",
      "Epoch: 002/025 | Batch 900/1000 | Loss: 0.235467\n",
      "Time elapsed: 0.00 min\n",
      "Epoch: 003/025 | Batch 000/1000 | Loss: 0.406710\n",
      "Epoch: 003/025 | Batch 100/1000 | Loss: 0.203223\n",
      "Epoch: 003/025 | Batch 200/1000 | Loss: 0.536993\n",
      "Epoch: 003/025 | Batch 300/1000 | Loss: 0.678042\n",
      "Epoch: 003/025 | Batch 400/1000 | Loss: 0.200907\n",
      "Epoch: 003/025 | Batch 500/1000 | Loss: 0.497400\n",
      "Epoch: 003/025 | Batch 600/1000 | Loss: 0.313752\n",
      "Epoch: 003/025 | Batch 700/1000 | Loss: 0.262755\n",
      "Epoch: 003/025 | Batch 800/1000 | Loss: 0.503326\n",
      "Epoch: 003/025 | Batch 900/1000 | Loss: 0.186589\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 004/025 | Batch 000/1000 | Loss: 0.632957\n",
      "Epoch: 004/025 | Batch 100/1000 | Loss: 0.174874\n",
      "Epoch: 004/025 | Batch 200/1000 | Loss: 0.343989\n",
      "Epoch: 004/025 | Batch 300/1000 | Loss: 0.452905\n",
      "Epoch: 004/025 | Batch 400/1000 | Loss: 0.160099\n",
      "Epoch: 004/025 | Batch 500/1000 | Loss: 0.342521\n",
      "Epoch: 004/025 | Batch 600/1000 | Loss: 0.231707\n",
      "Epoch: 004/025 | Batch 700/1000 | Loss: 0.210057\n",
      "Epoch: 004/025 | Batch 800/1000 | Loss: 0.285075\n",
      "Epoch: 004/025 | Batch 900/1000 | Loss: 0.083224\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 005/025 | Batch 000/1000 | Loss: 0.220922\n",
      "Epoch: 005/025 | Batch 100/1000 | Loss: 0.190299\n",
      "Epoch: 005/025 | Batch 200/1000 | Loss: 0.240597\n",
      "Epoch: 005/025 | Batch 300/1000 | Loss: 0.342301\n",
      "Epoch: 005/025 | Batch 400/1000 | Loss: 0.082967\n",
      "Epoch: 005/025 | Batch 500/1000 | Loss: 0.193291\n",
      "Epoch: 005/025 | Batch 600/1000 | Loss: 0.212525\n",
      "Epoch: 005/025 | Batch 700/1000 | Loss: 0.160593\n",
      "Epoch: 005/025 | Batch 800/1000 | Loss: 0.389491\n",
      "Epoch: 005/025 | Batch 900/1000 | Loss: 0.086147\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 006/025 | Batch 000/1000 | Loss: 0.116086\n",
      "Epoch: 006/025 | Batch 100/1000 | Loss: 0.041520\n",
      "Epoch: 006/025 | Batch 200/1000 | Loss: 0.364186\n",
      "Epoch: 006/025 | Batch 300/1000 | Loss: 0.324582\n",
      "Epoch: 006/025 | Batch 400/1000 | Loss: 0.217123\n",
      "Epoch: 006/025 | Batch 500/1000 | Loss: 0.262001\n",
      "Epoch: 006/025 | Batch 600/1000 | Loss: 0.353886\n",
      "Epoch: 006/025 | Batch 700/1000 | Loss: 0.346170\n",
      "Epoch: 006/025 | Batch 800/1000 | Loss: 0.159605\n",
      "Epoch: 006/025 | Batch 900/1000 | Loss: 0.167777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.01 min\n",
      "Epoch: 007/025 | Batch 000/1000 | Loss: 0.053774\n",
      "Epoch: 007/025 | Batch 100/1000 | Loss: 0.014403\n",
      "Epoch: 007/025 | Batch 200/1000 | Loss: 0.397144\n",
      "Epoch: 007/025 | Batch 300/1000 | Loss: 0.968657\n",
      "Epoch: 007/025 | Batch 400/1000 | Loss: 0.058434\n",
      "Epoch: 007/025 | Batch 500/1000 | Loss: 0.612499\n",
      "Epoch: 007/025 | Batch 600/1000 | Loss: 0.331236\n",
      "Epoch: 007/025 | Batch 700/1000 | Loss: 0.320124\n",
      "Epoch: 007/025 | Batch 800/1000 | Loss: 0.202638\n",
      "Epoch: 007/025 | Batch 900/1000 | Loss: 0.032726\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 008/025 | Batch 000/1000 | Loss: 0.011231\n",
      "Epoch: 008/025 | Batch 100/1000 | Loss: 0.017504\n",
      "Epoch: 008/025 | Batch 200/1000 | Loss: 0.227118\n",
      "Epoch: 008/025 | Batch 300/1000 | Loss: 0.194173\n",
      "Epoch: 008/025 | Batch 400/1000 | Loss: 0.028860\n",
      "Epoch: 008/025 | Batch 500/1000 | Loss: 0.274373\n",
      "Epoch: 008/025 | Batch 600/1000 | Loss: 0.140275\n",
      "Epoch: 008/025 | Batch 700/1000 | Loss: 0.127094\n",
      "Epoch: 008/025 | Batch 800/1000 | Loss: 0.188752\n",
      "Epoch: 008/025 | Batch 900/1000 | Loss: 0.057597\n",
      "Time elapsed: 0.01 min\n",
      "Epoch: 009/025 | Batch 000/1000 | Loss: 0.070667\n",
      "Epoch: 009/025 | Batch 100/1000 | Loss: 0.047191\n",
      "Epoch: 009/025 | Batch 200/1000 | Loss: 0.034137\n",
      "Epoch: 009/025 | Batch 300/1000 | Loss: 0.003844\n",
      "Epoch: 009/025 | Batch 400/1000 | Loss: 0.002017\n",
      "Epoch: 009/025 | Batch 500/1000 | Loss: 0.135464\n",
      "Epoch: 009/025 | Batch 600/1000 | Loss: 0.064173\n",
      "Epoch: 009/025 | Batch 700/1000 | Loss: 0.058682\n",
      "Epoch: 009/025 | Batch 800/1000 | Loss: 0.134526\n",
      "Epoch: 009/025 | Batch 900/1000 | Loss: 0.179470\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 010/025 | Batch 000/1000 | Loss: 0.037692\n",
      "Epoch: 010/025 | Batch 100/1000 | Loss: 0.046378\n",
      "Epoch: 010/025 | Batch 200/1000 | Loss: 0.243725\n",
      "Epoch: 010/025 | Batch 300/1000 | Loss: 0.014205\n",
      "Epoch: 010/025 | Batch 400/1000 | Loss: 0.008369\n",
      "Epoch: 010/025 | Batch 500/1000 | Loss: 0.399694\n",
      "Epoch: 010/025 | Batch 600/1000 | Loss: 0.097180\n",
      "Epoch: 010/025 | Batch 700/1000 | Loss: 0.086476\n",
      "Epoch: 010/025 | Batch 800/1000 | Loss: 0.052965\n",
      "Epoch: 010/025 | Batch 900/1000 | Loss: 0.062070\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 011/025 | Batch 000/1000 | Loss: 0.171494\n",
      "Epoch: 011/025 | Batch 100/1000 | Loss: 0.064982\n",
      "Epoch: 011/025 | Batch 200/1000 | Loss: 0.054310\n",
      "Epoch: 011/025 | Batch 300/1000 | Loss: 0.242364\n",
      "Epoch: 011/025 | Batch 400/1000 | Loss: 0.017320\n",
      "Epoch: 011/025 | Batch 500/1000 | Loss: 0.037326\n",
      "Epoch: 011/025 | Batch 600/1000 | Loss: 0.087753\n",
      "Epoch: 011/025 | Batch 700/1000 | Loss: 0.043781\n",
      "Epoch: 011/025 | Batch 800/1000 | Loss: 0.098656\n",
      "Epoch: 011/025 | Batch 900/1000 | Loss: 0.017381\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 012/025 | Batch 000/1000 | Loss: 0.008096\n",
      "Epoch: 012/025 | Batch 100/1000 | Loss: 0.046877\n",
      "Epoch: 012/025 | Batch 200/1000 | Loss: 0.005588\n",
      "Epoch: 012/025 | Batch 300/1000 | Loss: 0.040128\n",
      "Epoch: 012/025 | Batch 400/1000 | Loss: 0.023088\n",
      "Epoch: 012/025 | Batch 500/1000 | Loss: 0.011076\n",
      "Epoch: 012/025 | Batch 600/1000 | Loss: 0.046990\n",
      "Epoch: 012/025 | Batch 700/1000 | Loss: 0.057309\n",
      "Epoch: 012/025 | Batch 800/1000 | Loss: 0.020801\n",
      "Epoch: 012/025 | Batch 900/1000 | Loss: 0.041272\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 013/025 | Batch 000/1000 | Loss: 0.003490\n",
      "Epoch: 013/025 | Batch 100/1000 | Loss: 0.002600\n",
      "Epoch: 013/025 | Batch 200/1000 | Loss: 0.002337\n",
      "Epoch: 013/025 | Batch 300/1000 | Loss: 0.002194\n",
      "Epoch: 013/025 | Batch 400/1000 | Loss: 0.002086\n",
      "Epoch: 013/025 | Batch 500/1000 | Loss: 0.012520\n",
      "Epoch: 013/025 | Batch 600/1000 | Loss: 0.000284\n",
      "Epoch: 013/025 | Batch 700/1000 | Loss: 0.243463\n",
      "Epoch: 013/025 | Batch 800/1000 | Loss: 0.030677\n",
      "Epoch: 013/025 | Batch 900/1000 | Loss: 0.011464\n",
      "Time elapsed: 0.02 min\n",
      "Epoch: 014/025 | Batch 000/1000 | Loss: 0.006416\n",
      "Epoch: 014/025 | Batch 100/1000 | Loss: 0.009249\n",
      "Epoch: 014/025 | Batch 200/1000 | Loss: 0.000634\n",
      "Epoch: 014/025 | Batch 300/1000 | Loss: 0.003438\n",
      "Epoch: 014/025 | Batch 400/1000 | Loss: 0.138067\n",
      "Epoch: 014/025 | Batch 500/1000 | Loss: 0.023141\n",
      "Epoch: 014/025 | Batch 600/1000 | Loss: 0.002436\n",
      "Epoch: 014/025 | Batch 700/1000 | Loss: 0.001126\n",
      "Epoch: 014/025 | Batch 800/1000 | Loss: 0.101532\n",
      "Epoch: 014/025 | Batch 900/1000 | Loss: 0.123581\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 015/025 | Batch 000/1000 | Loss: 0.010683\n",
      "Epoch: 015/025 | Batch 100/1000 | Loss: 0.042912\n",
      "Epoch: 015/025 | Batch 200/1000 | Loss: 0.002367\n",
      "Epoch: 015/025 | Batch 300/1000 | Loss: 0.003545\n",
      "Epoch: 015/025 | Batch 400/1000 | Loss: 0.001087\n",
      "Epoch: 015/025 | Batch 500/1000 | Loss: 0.001955\n",
      "Epoch: 015/025 | Batch 600/1000 | Loss: 0.000880\n",
      "Epoch: 015/025 | Batch 700/1000 | Loss: 0.015049\n",
      "Epoch: 015/025 | Batch 800/1000 | Loss: 0.000082\n",
      "Epoch: 015/025 | Batch 900/1000 | Loss: 0.001318\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 016/025 | Batch 000/1000 | Loss: 0.000221\n",
      "Epoch: 016/025 | Batch 100/1000 | Loss: 0.000365\n",
      "Epoch: 016/025 | Batch 200/1000 | Loss: 0.000106\n",
      "Epoch: 016/025 | Batch 300/1000 | Loss: 0.000064\n",
      "Epoch: 016/025 | Batch 400/1000 | Loss: 0.007042\n",
      "Epoch: 016/025 | Batch 500/1000 | Loss: 0.000427\n",
      "Epoch: 016/025 | Batch 600/1000 | Loss: 0.000129\n",
      "Epoch: 016/025 | Batch 700/1000 | Loss: 0.000301\n",
      "Epoch: 016/025 | Batch 800/1000 | Loss: 0.000016\n",
      "Epoch: 016/025 | Batch 900/1000 | Loss: 0.000651\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 017/025 | Batch 000/1000 | Loss: 0.000108\n",
      "Epoch: 017/025 | Batch 100/1000 | Loss: 0.000074\n",
      "Epoch: 017/025 | Batch 200/1000 | Loss: 0.000032\n",
      "Epoch: 017/025 | Batch 300/1000 | Loss: 0.000029\n",
      "Epoch: 017/025 | Batch 400/1000 | Loss: 0.000011\n",
      "Epoch: 017/025 | Batch 500/1000 | Loss: 0.000115\n",
      "Epoch: 017/025 | Batch 600/1000 | Loss: 0.000042\n",
      "Epoch: 017/025 | Batch 700/1000 | Loss: 0.000259\n",
      "Epoch: 017/025 | Batch 800/1000 | Loss: 0.000003\n",
      "Epoch: 017/025 | Batch 900/1000 | Loss: 0.000130\n",
      "Time elapsed: 0.03 min\n",
      "Epoch: 018/025 | Batch 000/1000 | Loss: 0.000099\n",
      "Epoch: 018/025 | Batch 100/1000 | Loss: 0.000021\n",
      "Epoch: 018/025 | Batch 200/1000 | Loss: 0.000014\n",
      "Epoch: 018/025 | Batch 300/1000 | Loss: 0.000024\n",
      "Epoch: 018/025 | Batch 400/1000 | Loss: 0.000008\n",
      "Epoch: 018/025 | Batch 500/1000 | Loss: 0.000064\n",
      "Epoch: 018/025 | Batch 600/1000 | Loss: 0.000028\n",
      "Epoch: 018/025 | Batch 700/1000 | Loss: 0.000220\n",
      "Epoch: 018/025 | Batch 800/1000 | Loss: 0.000002\n",
      "Epoch: 018/025 | Batch 900/1000 | Loss: 0.000073\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 019/025 | Batch 000/1000 | Loss: 0.000081\n",
      "Epoch: 019/025 | Batch 100/1000 | Loss: 0.000012\n",
      "Epoch: 019/025 | Batch 200/1000 | Loss: 0.000009\n",
      "Epoch: 019/025 | Batch 300/1000 | Loss: 0.000019\n",
      "Epoch: 019/025 | Batch 400/1000 | Loss: 0.000007\n",
      "Epoch: 019/025 | Batch 500/1000 | Loss: 0.000044\n",
      "Epoch: 019/025 | Batch 600/1000 | Loss: 0.000021\n",
      "Epoch: 019/025 | Batch 700/1000 | Loss: 0.000184\n",
      "Epoch: 019/025 | Batch 800/1000 | Loss: 0.000001\n",
      "Epoch: 019/025 | Batch 900/1000 | Loss: 0.000048\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 020/025 | Batch 000/1000 | Loss: 0.000067\n",
      "Epoch: 020/025 | Batch 100/1000 | Loss: 0.000007\n",
      "Epoch: 020/025 | Batch 200/1000 | Loss: 0.000007\n",
      "Epoch: 020/025 | Batch 300/1000 | Loss: 0.000015\n",
      "Epoch: 020/025 | Batch 400/1000 | Loss: 0.000006\n",
      "Epoch: 020/025 | Batch 500/1000 | Loss: 0.000032\n",
      "Epoch: 020/025 | Batch 600/1000 | Loss: 0.000017\n",
      "Epoch: 020/025 | Batch 700/1000 | Loss: 0.000155\n",
      "Epoch: 020/025 | Batch 800/1000 | Loss: 0.000001\n",
      "Epoch: 020/025 | Batch 900/1000 | Loss: 0.000034\n",
      "Time elapsed: 0.04 min\n",
      "Epoch: 021/025 | Batch 000/1000 | Loss: 0.000056\n",
      "Epoch: 021/025 | Batch 100/1000 | Loss: 0.000005\n",
      "Epoch: 021/025 | Batch 200/1000 | Loss: 0.000005\n",
      "Epoch: 021/025 | Batch 300/1000 | Loss: 0.000013\n",
      "Epoch: 021/025 | Batch 400/1000 | Loss: 0.000005\n",
      "Epoch: 021/025 | Batch 500/1000 | Loss: 0.000025\n",
      "Epoch: 021/025 | Batch 600/1000 | Loss: 0.000014\n",
      "Epoch: 021/025 | Batch 700/1000 | Loss: 0.000133\n",
      "Epoch: 021/025 | Batch 800/1000 | Loss: 0.000001\n",
      "Epoch: 021/025 | Batch 900/1000 | Loss: 0.000026\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 022/025 | Batch 000/1000 | Loss: 0.000047\n",
      "Epoch: 022/025 | Batch 100/1000 | Loss: 0.000004\n",
      "Epoch: 022/025 | Batch 200/1000 | Loss: 0.000004\n",
      "Epoch: 022/025 | Batch 300/1000 | Loss: 0.000011\n",
      "Epoch: 022/025 | Batch 400/1000 | Loss: 0.000004\n",
      "Epoch: 022/025 | Batch 500/1000 | Loss: 0.000018\n",
      "Epoch: 022/025 | Batch 600/1000 | Loss: 0.000011\n",
      "Epoch: 022/025 | Batch 700/1000 | Loss: 0.000114\n",
      "Epoch: 022/025 | Batch 800/1000 | Loss: 0.000001\n",
      "Epoch: 022/025 | Batch 900/1000 | Loss: 0.000016\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 023/025 | Batch 000/1000 | Loss: 0.000040\n",
      "Epoch: 023/025 | Batch 100/1000 | Loss: 0.000002\n",
      "Epoch: 023/025 | Batch 200/1000 | Loss: 0.000003\n",
      "Epoch: 023/025 | Batch 300/1000 | Loss: 0.000009\n",
      "Epoch: 023/025 | Batch 400/1000 | Loss: 0.000003\n",
      "Epoch: 023/025 | Batch 500/1000 | Loss: 0.000012\n",
      "Epoch: 023/025 | Batch 600/1000 | Loss: 0.000009\n",
      "Epoch: 023/025 | Batch 700/1000 | Loss: 0.000097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023/025 | Batch 800/1000 | Loss: 0.000000\n",
      "Epoch: 023/025 | Batch 900/1000 | Loss: 0.000009\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 024/025 | Batch 000/1000 | Loss: 0.000035\n",
      "Epoch: 024/025 | Batch 100/1000 | Loss: 0.000001\n",
      "Epoch: 024/025 | Batch 200/1000 | Loss: 0.000002\n",
      "Epoch: 024/025 | Batch 300/1000 | Loss: 0.000008\n",
      "Epoch: 024/025 | Batch 400/1000 | Loss: 0.000003\n",
      "Epoch: 024/025 | Batch 500/1000 | Loss: 0.000009\n",
      "Epoch: 024/025 | Batch 600/1000 | Loss: 0.000008\n",
      "Epoch: 024/025 | Batch 700/1000 | Loss: 0.000082\n",
      "Epoch: 024/025 | Batch 800/1000 | Loss: 0.000000\n",
      "Epoch: 024/025 | Batch 900/1000 | Loss: 0.000007\n",
      "Time elapsed: 0.06 min\n",
      "Epoch: 025/025 | Batch 000/1000 | Loss: 0.000030\n",
      "Epoch: 025/025 | Batch 100/1000 | Loss: 0.000001\n",
      "Epoch: 025/025 | Batch 200/1000 | Loss: 0.000002\n",
      "Epoch: 025/025 | Batch 300/1000 | Loss: 0.000006\n",
      "Epoch: 025/025 | Batch 400/1000 | Loss: 0.000002\n",
      "Epoch: 025/025 | Batch 500/1000 | Loss: 0.000007\n",
      "Epoch: 025/025 | Batch 600/1000 | Loss: 0.000007\n",
      "Epoch: 025/025 | Batch 700/1000 | Loss: 0.000070\n",
      "Epoch: 025/025 | Batch 800/1000 | Loss: 0.000000\n",
      "Epoch: 025/025 | Batch 900/1000 | Loss: 0.000005\n",
      "Time elapsed: 0.06 min\n",
      "Total Training Time: 0.06 min\n",
      "Train error : 0.0% \n",
      "Test error : 20.1%\n",
      "The total number of the parameters is: 204312\n"
     ]
    }
   ],
   "source": [
    "# calculate the standard deviation:\n",
    "train_errors=[]\n",
    "test_errors=[]\n",
    "for num in range(10):\n",
    "    N_PAIRS = 1000\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N_PAIRS)\n",
    "    tran_train_input=train_input.view(-1,2*14*14)\n",
    "    tran_test_input=test_input.view(-1,2*14*14)\n",
    "    my_model = MLP_Net()\n",
    "    # train the model\n",
    "    my_model.trainer(tran_train_input, train_target)\n",
    "    # output the train error and test error\n",
    "    print(\"Train error : %.1f%% \\nTest error : %.1f%%\" %\n",
    "      (my_model.compute_error(tran_train_input, train_target),\n",
    "       my_model.compute_error(tran_test_input, test_target)))\n",
    "    print(\"The total number of the parameters is: %d\" % (sum(p.numel() for p in my_model.parameters())))\n",
    "    train_errors.append(my_model.compute_error(tran_train_input, train_target))\n",
    "    test_errors.append(my_model.compute_error(tran_test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of train error: 0.2683281572999748\n",
      "The standard deviation of test error: 1.3009227494359539\n",
      "The mean of train error: 0.1\n",
      "The mean of test error: 19.06\n"
     ]
    }
   ],
   "source": [
    "print('The standard deviation of train error:',np.std(train_errors))\n",
    "print('The standard deviation of test error:',np.std(test_errors))\n",
    "print('The mean of train error:',np.mean(train_errors))\n",
    "print('The mean of test error:',np.mean(test_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
